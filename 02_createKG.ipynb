{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "class EPKG():\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.df = None\n",
    "        self.columns = [\n",
    "               'GUID', 'Name', 'ReportName', 'Title',\n",
    "               'YearOfPublication', \n",
    "               'LinkingUri', \n",
    "               'LinkingUrl', \n",
    "               'ServerRelativeUrl', \n",
    "               'ServerRedirectedEmbedUri',\n",
    "               'ServerRedirectedEmbedUrl', \n",
    "\n",
    "               'Created', \n",
    "               'Length', \n",
    "\n",
    "               'Basin', 'Block', 'WellName', \n",
    "               'ReportAuthor',\n",
    "               'Contractors', \n",
    "\n",
    "               'TypeofFormat', 'TypesOfReport', 'StatusOfReport', 'Fields',\n",
    "\n",
    "               'Function', 'TypeOfFile',\n",
    "               ]\n",
    "        self.accepted_ext = [\n",
    "         'DOC', 'DOCX', 'PDF', 'XLS', 'doc', 'docx', 'pdf', 'plt', 'ppt', 'pptx', 'txt', 'xls', 'xlsx',\n",
    "        ]\n",
    "        self.load_data()\n",
    "        self.filter_data()\n",
    "        self.file_entity()\n",
    "        self.convert_dict2list()\n",
    "        self.create_single_entity_df()\n",
    "\n",
    "    def load_data(self, file_path:str='data/raw/all_data.json'):\n",
    "        with open(file_path) as f:\n",
    "            self.data = json.load(f)\n",
    "            self.df = pd.DataFrame(self.data).T.reset_index()\n",
    "            self.df = self.df[self.columns]\n",
    "\n",
    "    def filter_data(self):\n",
    "        self.df = self.df[(self.df['Name'].str.split('.').str[-1]).isin(self.accepted_ext)]\n",
    "        self.df = self.df.reset_index(drop=True)\n",
    "        \n",
    "# File Entity\n",
    "    def file_entity(self):\n",
    "        selected_columns = ['Name', 'GUID', 'ReportName', 'Title', 'YearOfPublication', \n",
    "                 'LinkingUri', 'LinkingUrl', 'ServerRelativeUrl', 'ServerRedirectedEmbedUri', 'ServerRedirectedEmbedUrl',\n",
    "                 'Created', 'Length', \n",
    "                 ]\n",
    "        self.file_entities =  self.df[selected_columns]\n",
    "\n",
    "    def create_single_entity_df(self):\n",
    "        # Basin Entity\n",
    "        self.basin_cols = ['Name', 'GUID', 'Basin']\n",
    "        self.basin_df = self.df[self.basin_cols].explode('Basin')\n",
    "        self.unique_basin = self.basin_df['Basin'].unique()\n",
    "        # Block Entity\n",
    "        self.block_cols = ['Name', 'GUID', 'Block', 'Basin']\n",
    "        self.block_df = self.df[self.block_cols].explode('Block')\n",
    "        self.unique_block = self.block_df['Block'].unique()\n",
    "        # Well Entity\n",
    "        self.well_cols = ['Name', 'GUID', 'WellName', 'Block', 'Basin']\n",
    "        self.well_df = self.df[self.well_cols].explode('WellName')\n",
    "        self.unique_well = self.well_df['WellName'].unique()\n",
    "        # Author Entity\n",
    "        self.author_cols = ['Name', 'GUID', 'ReportAuthor']\n",
    "        self.author_df = self.df[self.author_cols].explode('ReportAuthor')\n",
    "        for i in range(len(self.author_df)):\n",
    "            # print(type(self.author_df['ReportAuthor'][i]))\n",
    "            if self.author_df['ReportAuthor'][i] is not None and ' - ' in self.author_df['ReportAuthor'][i]:\n",
    "                self.author_df['ReportAuthor'][i] = self.author_df['ReportAuthor'][i].split(' - ')\n",
    "            if self.author_df['ReportAuthor'][i] in ['113-BD-1X', '107-PL-1X']:\n",
    "                self.author_df['ReportAuthor'][i] = None\n",
    "            if self.author_df['ReportAuthor'][i] is not None and ' - ' in self.author_df['ReportAuthor'][i]:\n",
    "                self.author_df['ReportAuthor'][i] = self.author_df['ReportAuthor'][i].split(' - ')\n",
    "        self.author_df = self.author_df.explode('ReportAuthor')\n",
    "        self.unique_author = self.author_df['ReportAuthor'].unique()\n",
    "        # Contractor Entit\n",
    "        self.contractor_cols = ['Name', 'GUID', 'Contractors']\n",
    "        self.contractor_df = self.df[self.contractor_cols].explode('Contractors')\n",
    "        self.unique_contractor = self.contractor_df['Contractors'].unique()\n",
    "        # TypeofFormat Entity\n",
    "        self.type_of_format_cols = ['Name', 'GUID', 'TypeofFormat']\n",
    "        self.type_of_format_df = self.df[self.type_of_format_cols].explode('TypeofFormat')\n",
    "        self.unique_type_of_format = self.type_of_format_df['TypeofFormat'].unique()\n",
    "        # TypesOfReport Entity\n",
    "        self.types_of_report_cols = ['Name', 'GUID', 'TypesOfReport']\n",
    "        self.types_of_report_df = self.df[self.types_of_report_cols].explode('TypesOfReport')\n",
    "        self.unique_types_of_report = self.types_of_report_df['TypesOfReport'].unique()\n",
    "        # StatusOfReport Entity\n",
    "        self.status_of_report_cols = ['Name', 'GUID', 'StatusOfReport']\n",
    "        self.status_of_report_df = self.df[self.status_of_report_cols].explode('StatusOfReport')\n",
    "        self.unique_status_of_report = self.status_of_report_df['StatusOfReport'].unique()\n",
    "        # Fields Entity\n",
    "        self.fields_cols = ['Name', 'GUID', 'Fields']\n",
    "        self.fields_df = self.df[self.fields_cols].explode('Fields')\n",
    "        self.unique_fields = self.fields_df['Fields'].unique()\n",
    "        # Function Entity\n",
    "        self.function_cols = ['Name', 'GUID', 'Function']\n",
    "        self.function_df = self.df[self.function_cols].explode('Function')\n",
    "        self.unique_function = self.function_df['Function'].unique()\n",
    "        # TypeOfFile Entity\n",
    "        self.type_of_file_cols = ['Name', 'GUID', 'TypeOfFile']\n",
    "        self.type_of_file_df = self.df[self.type_of_file_cols].explode('TypeOfFile')\n",
    "        self.unique_type_of_file = self.type_of_file_df['TypeOfFile'].unique()\n",
    "\n",
    "    def convert_dict2list(self):\n",
    "        for col_name in ['Basin', 'Block', 'WellName', 'ReportAuthor', 'Contractors', 'TypeofFormat', 'TypesOfReport', 'StatusOfReport', 'Fields', 'Function', 'TypeOfFile']:\n",
    "            # Check if column is a dictionary\n",
    "            if isinstance(self.df[col_name][0], dict):\n",
    "                self.__convert_dict2list(col_name)\n",
    "\n",
    "    def __convert_dict2list(self, col_name:str):\n",
    "        print(f\"Converting {col_name} to list\")\n",
    "        column = self.df[col_name]\n",
    "\n",
    "        if col_name == \"Basin\":\n",
    "            fixed_value = list(column[0].values())\n",
    "\n",
    "        for i, col_value in enumerate(column):\n",
    "            if col_value is None and col_name == \"Basin\":\n",
    "                column[i] = fixed_value\n",
    "            elif col_value is None and col_name != \"Basin\":\n",
    "                column[i] = []\n",
    "            else:\n",
    "                column[i] = list(column[i].values())\n",
    "\n",
    "        self.df[col_name] = column\n",
    "\n",
    "    def __save_csv(self, data:pd.DataFrame, file_path:str):\n",
    "        data.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Basin to list\n",
      "Converting Block to list\n",
      "Converting TypeofFormat to list\n",
      "Converting TypesOfReport to list\n",
      "Converting Fields to list\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['CCOP', None, 'Nguyen Thanh Tung', 'Nguyen Tien Thinh',\n",
       "       'Chu Duc Quang',\n",
       "       'Nguyen The Hung, Luu Thanh Hung va nhung nguoi khac',\n",
       "       'Nguyen Thi Dau', 'VPI Labs', 'Do Bat', 'Nguyen Manh Hung',\n",
       "       'Nguyen Thi Tham', 'Bui Thi Ngoc Phuong',\n",
       "       'Edi W. Jatmiko and Tidar A.B.Nurgrojo', 'Ha Quoc Quan',\n",
       "       'Nguyen Huy Ngoc, Jamin Jamil  Bin Mohd Idris', 'Le Quang Chung',\n",
       "       'Roszendy b.Danial', 'Mohd Zafuan Che Zulkifli',\n",
       "       'International logging', 'Norkhairil B Mohamad',\n",
       "       'Jamin Jamin Bin Mohd Idris', 'PVEP', 'International Logging',\n",
       "       'VAST', 'Bui  Thi Ngoc Phuong', 'Hoang Manh Tan',\n",
       "       'Nguyen Hong Minh and Hoang Manh Tan', 'Nguyen Van Giap',\n",
       "       'Nguyen Trong Tri', 'Nguyen Duc Hung', 'Nguyen Dac The',\n",
       "       'Nguyen Thi Bich Ha',\n",
       "       'Vu Tien Lang, Cao Duc Thang, Nguyen Ngoc Minh, Nguyen Duc Hung, Dinh Van Huy',\n",
       "       'EPC-VPI', 'PTSC Marine/OGS', 'Luu Khac Thieu', 'Pham Van Tuan',\n",
       "       'Hoang Van Thach', 'J.L. PITTION',\n",
       "       'Do Bat, Phan Huy Quynh, Luu Khac Thieu...', 'Nguyen Van Vien',\n",
       "       'Nguyen Quang Trong', 'Nguyen Duy Sam', '107-PL-1X',\n",
       "       'Fairfield Viet Nam', 'Nguyen Duc Huy', 'Nguyen Huy Ngoc',\n",
       "       'Ch.De Cruz', 'A. Bachelot/L.Durand', 'B.LAMBERT',\n",
       "       'Bingjian Li and Phung Nguyen Thanh', 'Le T. Tuyet Hong',\n",
       "       'Ngô Xuân Vinh', 'Bingjian Li and Pham The Phuong',\n",
       "       'Nguyen Duc Hung, Nguyen Van Thang, Nguyen Ngoc Hoan',\n",
       "       'Nguyen Thi Tram, Nguyen Van Thang, Nguyen Ngoc Hoan',\n",
       "       'Tran Duc Ninh', 'Nguyen Thanh Lam', 'Le Thi Tuyet Hong',\n",
       "       'Nguyen Van Hoi', 'Nguyen Thanh Tuyen', 'Nguyen Van Su',\n",
       "       'Dao Thu Ha ', 'Nguyen Ngoc Hoan',\n",
       "       'Ngo Xuan Vinh, Duong Duc Quang', 'Ngô Xuân vinh',\n",
       "       'Hoang Anh Tuan', 'Ashiq Hussain', 'Anton Lehner',\n",
       "       'A. Wrightstone', 'DR J.P.REXILIUS', 'Mona A. Rachmalia',\n",
       "       'Ngo Xuan Vinh', 'Pham Xuan Kim', 'Phan Van Thang',\n",
       "       'Nguyen Hong Minh', 'R. Gambini', 'Pham Thi Toan',\n",
       "       'SergeynVystavnoy', '113-BD-1X',\n",
       "       'Le Thi Tuyet Hong, Nguyen Van Sang Vo', 'Nguyen ThI Tham',\n",
       "       'Sirajetdin Akhmedov', 'Phung Sy Tai', 'DAVID A. HOWARD',\n",
       "       'Martin Smith', 'S: Lowe', 'VPI', 'Amma Whear',\n",
       "       'H.Nicholson, K.Amiri-Garroussi & N.H.Oxtoby',\n",
       "       'A.D. Horbury & D.C. Holland', 'I Stockden & P Mitchell',\n",
       "       ' Nguyen Thanh Tuyen', 'J.Ince', 'H.J. Salt & K.J. Sincock',\n",
       "       'A.D.Hobury', 'Tran Cong Tao', 'Le Van Hung', 'Phan Xuan Kim',\n",
       "       'Nguyen Huu Liem', 'Pham Hong Que', 'Pham Quang Trung',\n",
       "       'Ho Tan Loc', 'Chu The Phong', 'Le Hoan Quyen', 'A. THOMAS',\n",
       "       'Nguyen Thi Bich Phuong', 'Nguyen Hue Khanh', 'Tran Van Tri'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPProcessing = EPKG()\n",
    "EPProcessing.unique_author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "booksage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
